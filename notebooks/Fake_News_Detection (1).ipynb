{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSZPYVGKaxZN"
   },
   "source": [
    "## Step 1: Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzTd1RscYbYp",
    "outputId": "07efe2e7-b45c-416e-ebdc-e9eaa3c81797"
   },
   "outputs": [],
   "source": [
    "!pip install feedparser beautifulsoup4 scikit-learn requests python-dateutil --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjPPLcqPa56m"
   },
   "source": [
    "## Step 2: Imports Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UAJ8ulZ4Yy7e"
   },
   "outputs": [],
   "source": [
    "import re, requests, feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser as dtparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtulBq3vbAhP"
   },
   "source": [
    "## Step 3: Load RSS Feed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4GWRGW0Y2YH",
    "outputId": "6696cedf-89e6-4134-ba2f-2c903301e445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 34\n",
      "Sample title: ভারতের প্রধানমন্ত্রী মোদির সিঙ্গুর সফর, শিল্প নিয়ে আশার কথা শোনা গেল না - প্রথম আলো\n"
     ]
    }
   ],
   "source": [
    "RSS_URL = \"https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx1YlY4U0FtVnVHZ0pWVXlnQVAB?hl=bn&gl=BD&ceid=BD:bn\"\n",
    "rss = feedparser.parse(RSS_URL)\n",
    "entries = rss.entries\n",
    "print(\"Entries:\", len(entries))\n",
    "print(\"Sample title:\", entries[0].title if entries else \"No entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM0G34W2bJ5X"
   },
   "source": [
    "## Step 4: Creating Helpers Functions (Normalize Text, Bangla Text, Fetching title from URL and Parse Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dsr_vTPrY4YT"
   },
   "outputs": [],
   "source": [
    "def norm_text(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def bn_norm(s: str) -> str:\n",
    "    s = (s or \"\").strip()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)  #Regex for removing Punchuations\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.lower()\n",
    "\n",
    "def fetch_title_from_url(url: str) -> str:\n",
    "    try:\n",
    "        html = requests.get(url, timeout=8).text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        t = soup.title.string if soup.title and soup.title.string else \"\"\n",
    "        return norm_text(t)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def parse_time(e):\n",
    "    for key in (\"published\", \"updated\"):\n",
    "        if hasattr(e, key):\n",
    "            try:\n",
    "                return dtparse.parse(getattr(e, key))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AkQZ3I6b1b-"
   },
   "source": [
    "## Step 5: Prepare Feed Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kV6a2dzY6jn",
    "outputId": "0f6b20b3-4544-4dc8-94c2-06e5e0780aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared feed items: 34\n"
     ]
    }
   ],
   "source": [
    "feed_items = []\n",
    "for e in entries:\n",
    "    title = norm_text(getattr(e, \"title\", \"\")).strip()\n",
    "    link  = getattr(e, \"link\", \"\")\n",
    "    dom   = urlparse(link).netloc.lower()\n",
    "    ts    = parse_time(e)\n",
    "    feed_items.append({\"title\": title, \"link\": link, \"domain\": dom, \"time\": ts})\n",
    "print(\"Prepared feed items:\", len(feed_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_Dkkpjrb6Zg"
   },
   "source": [
    "## Step 6: TF IDF fit on Feed Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mst1f0BZY87E",
    "outputId": "f447c48c-730d-4ba8-cdc5-f2b24dfb6087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer vocabulary size: 211\n"
     ]
    }
   ],
   "source": [
    "feed_titles = [i[\"title\"] for i in feed_items if i[\"title\"]]\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=None)\n",
    "_ = vectorizer.fit(feed_titles or [\"খবর\"])\n",
    "print(\"Vectorizer vocabulary size:\", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "094S-eNZcFYj"
   },
   "source": [
    "## Step 7: Ask user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dY4s3tq1ZBXu",
    "outputId": "342e9750-0372-4841-bf29-424b2f57d9ed"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a news TITLE or URL:  https://www.prothomalo.com/bangladesh/district/6wx8ewcvor\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Enter a news TITLE or URL: \").strip()\n",
    "is_url = user_input.startswith(\"http://\") or user_input.startswith(\"https://\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4OAgUV5rkmW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ft-70MwcMkF"
   },
   "source": [
    "## Step 8: Rsolve input to title or URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WJjAHeSZD21",
    "outputId": "40475709-4d9e-409d-a0df-aa97c09a5f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved title: মৌলভীবাজারে তারেক রহমানের জনসভায় ব্যাপক লোকসমাগমের প্রস্তুতি | প্রথম আলো\n"
     ]
    }
   ],
   "source": [
    "if is_url:\n",
    "    user_title = fetch_title_from_url(user_input) or norm_text(urlparse(user_input).path.replace(\"/\", \" \"))\n",
    "    user_domain = urlparse(user_input).netloc.lower()\n",
    "else:\n",
    "    user_title = norm_text(user_input)\n",
    "    user_domain = \"\"\n",
    "print(\"Resolved title:\", user_title[:120] + (\"...\" if len(user_title)>120 else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxmUHmVycZtn"
   },
   "source": [
    "## Step 9: Find best match in feed by cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19-A-1amZGpl",
    "outputId": "3ffc3dcb-c118-4ee2-dc46-a7f7881051fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sim: 0.2623\n",
      "Matched: ইউরোপের যে ৫ দেশে পরিবারসহ পড়াশোনার সুযোগ - প্রথম আলো\n"
     ]
    }
   ],
   "source": [
    "def best_match(title: str):\n",
    "    if not feed_items or not title:\n",
    "        return None, 0.0\n",
    "    qv = vectorizer.transform([title])\n",
    "    cv = vectorizer.transform([i[\"title\"] for i in feed_items])\n",
    "    sims = cosine_similarity(qv, cv).ravel()\n",
    "    idx = sims.argmax()\n",
    "    return feed_items[idx], float(sims[idx])\n",
    "\n",
    "match_item, sim = best_match(user_title)\n",
    "print(\"Best sim:\", round(sim, 4))\n",
    "if match_item:\n",
    "    print(\"Matched:\", match_item[\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfukQbqlce-J"
   },
   "source": [
    "## Step 10: Extra strong title/subphrase signal (partial-title fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGCF2oLHZJCh",
    "outputId": "9d66abd9-bd92-4b3c-b328-dfd915a6314a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong title match: False\n"
     ]
    }
   ],
   "source": [
    "norm_user  = bn_norm(user_title)\n",
    "norm_match = bn_norm(match_item[\"title\"]) if match_item else \"\"\n",
    "strong_title_match = False\n",
    "if norm_user and norm_match:\n",
    "    toks = norm_user.split()\n",
    "    strong_title_match = (norm_user in norm_match) or all(t in norm_match for t in toks)\n",
    "print(\"Strong title match:\", strong_title_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX_WKCSjchmp"
   },
   "source": [
    "## Step 11: Presence flags and recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKZKMJnvZLOK",
    "outputId": "2e880a3b-485e-40bf-f319-0fdb1ad50a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flags → in_title: False | in_url: False | in_domain: False | recency(h): 32.2\n"
     ]
    }
   ],
   "source": [
    "def hours_ago(t):\n",
    "    if not t:\n",
    "        return None\n",
    "    now = datetime.now(timezone.utc)\n",
    "    if t.tzinfo is None:\n",
    "        t = t.replace(tzinfo=timezone.utc)\n",
    "    return max(0.0, (now - t).total_seconds()/3600.0)\n",
    "\n",
    "# Title presence: decent similarity OR strong subphrase match\n",
    "in_feed_by_title = (sim >= 0.50) or strong_title_match\n",
    "\n",
    "# URL presence: only for URL input (exact link match)\n",
    "in_feed_by_url = False\n",
    "if is_url:\n",
    "    in_feed_by_url = any(user_input.strip() == i[\"link\"] for i in feed_items)\n",
    "\n",
    "# Domain presence:\n",
    "if is_url:\n",
    "    domain_in_feed = any(i[\"domain\"] == user_domain for i in feed_items)\n",
    "else:\n",
    "    domain_in_feed = bool(match_item)\n",
    "\n",
    "recency_hours = hours_ago(match_item[\"time\"]) if match_item else None\n",
    "print(\"Flags → in_title:\", in_feed_by_title, \"| in_url:\", in_feed_by_url, \"| in_domain:\", domain_in_feed, \"| recency(h):\", None if recency_hours is None else round(recency_hours,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxGqciM0c1F0"
   },
   "source": [
    "## Step 12: Weight calculation (0..1) before DT decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFgpJuxDZQWR",
    "outputId": "4663d963-e2b9-4d41-b937-616d4d0cc3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sim': 0.262, 'presence': 0.0, 'recency': 0.329, 'weight': 0.19}\n"
     ]
    }
   ],
   "source": [
    "w_sim      = sim\n",
    "w_presence = (0.5 if in_feed_by_title else 0.0) + (0.3 if in_feed_by_url else 0.0) + (0.2 if domain_in_feed else 0.0)\n",
    "if strong_title_match:\n",
    "    w_presence += 0.2  # bonus for subphrase containment\n",
    "w_recency  = 0.0 if recency_hours is None else max(0.0, 1.0 - min(recency_hours, 48)/48.0)  # fresh→1, >48h→0\n",
    "raw_weight = 0.6*w_sim + 0.3*w_presence + 0.1*w_recency\n",
    "weight     = max(0.0, min(1.0, raw_weight))\n",
    "print({\"sim\": round(w_sim,3), \"presence\": round(w_presence,3), \"recency\": round(w_recency,3), \"weight\": round(weight,3)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZELFovIDc4mI"
   },
   "source": [
    "## Step 13: Decision Tree (rules) → Fake / Neutral / Well Sourced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9EvaDz_ZSex",
    "outputId": "a5dc5195-cff2-4e84-ba89-f6dd5b2d3b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Neutral\n"
     ]
    }
   ],
   "source": [
    "def dt_decide(sim, in_title, in_url, in_domain, recency_h, weight, strong_title_match):\n",
    "    # Node 1: strong textual match OR strong subphrase match (partial-title)\n",
    "    if (in_title and sim >= 0.70) or strong_title_match:\n",
    "        if in_url or (recency_h is not None and recency_h <= 72):\n",
    "            return \"Well Sourced\"\n",
    "        return \"Neutral\"\n",
    "    # Node 2: moderate similarity + domain present (feed-backed)\n",
    "    if sim >= 0.50 and in_domain:\n",
    "        return \"Well Sourced\" if weight >= 0.60 else \"Neutral\"\n",
    "    # Node 3: weak similarity, no presence anywhere\n",
    "    if sim < 0.25 and (not in_title) and (not in_domain):\n",
    "        return \"Fake\"\n",
    "    # Default\n",
    "    return \"Neutral\"\n",
    "\n",
    "final_label = dt_decide(sim, in_feed_by_title, in_feed_by_url, domain_in_feed, recency_hours, weight, strong_title_match)\n",
    "print(\"Label:\", final_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZoH4Cv6dCMn"
   },
   "source": [
    "## Step 14: Output Summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhsVhYmEgJeI",
    "outputId": "a16abd2a-666e-4cc4-c772-1005aa5052a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULT ===\n",
      "Label: Neutral\n",
      "Weight (0..1): 0.19\n",
      "Matched Feed Title: ইউরোপের যে ৫ দেশে পরিবারসহ পড়াশোনার সুযোগ - প্রথম আলো\n",
      "Matched Feed Link : https://news.google.com/rss/articles/CBMia0FVX3lxTFBKMThvYm9IRnM2Q3dHODl4QlNzYTVZb2VFR3FuMThqU0RVZjFHeUR1MUNWcGdQNC1VWWNnV2VBenUxS1A0OTRJay1tdXU3YUI1RjBxN2NqU2l0SGV0bFJ0cG9IQzZFbVhYQ0JF0gF4QVVfeXFMTmNGZDFaQmhxUFBFQUJ5ampxU0hSTHExM3hocVkxcnRuRWVyQnRqd2s1bnZnN2RSZ0NHM3Utek9NMUpMSVItRW5PMF9ha1RiYXJWbzl0RzdXVGp6THZQTTBSQmxTa2FsMlJjOFloNmVhcldkalppdG03?oc=5\n",
      "Similarity       : 0.262\n",
      "Recency (hours)  : 32.2\n",
      "Signals → in_title: False | in_url: False | domain_in_feed: False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== RESULT ===\")\n",
    "\n",
    "if 'final_label' not in globals():\n",
    "    print(\"Label: Not computed (please run all previous cells)\")\n",
    "else:\n",
    "    print(\"Label:\", final_label)\n",
    "    print(\"Weight (0..1):\", round(weight, 3))\n",
    "\n",
    "    if match_item:\n",
    "        print(\"Matched Feed Title:\", match_item[\"title\"])\n",
    "        print(\"Matched Feed Link :\", match_item[\"link\"])\n",
    "        print(\"Similarity       :\", round(sim, 3))\n",
    "        print(\"Recency (hours)  :\", None if recency_hours is None else round(recency_hours, 1))\n",
    "\n",
    "    print(\"Signals → in_title:\", in_feed_by_title,\n",
    "          \"| in_url:\", in_feed_by_url,\n",
    "          \"| domain_in_feed:\", domain_in_feed)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
